Framebuffer

A framebuffer is not actually a buffer. It's an abstraction for an object that defines parameters for a draw operation. It's a small object that holds one or more attachments, which are themselves the actual buffers. Understand the framebuffer as a C struct with many fields. Each field (each attachment in OpenGL terms) can be a pointer to a render buffer, texture, depth buffer, etc.

Texture

An array of standard pixels. This is an actual buffer and can be attached to a framebuffer as the destination of pixels being drawn. Each pixel in a texture typically contains color components and an alpha value (a pixel in the texture can be translated from and into an RGBA quad with 4 floats).

After drawing to the framebuffer that contains a texture attached, it's possible to read pixels from the texture to use in another draw operation. This allows, for instance, multi-pass drawing or drawing a scene inside another scene.

Textures can be attached to a shader program and used as samplers.

Renderbuffer

An array of native pixels. The renderbuffer is just like a texture, but stores pixels using an internal format. It's optimized for pixel transfer operations. It can be attached to a framebuffer as the destination of pixels being drawn, then quickly copied to the viewport or another framebuffer. This allows implementing of double buffer algorithms, where the next scene is drawn while the previous scene is exhibited.

A renderbuffer can also be used to store depth and stencil information that is used just for a single draw procedure. This is possible because only the implementation itself needs to read renderbuffer data, and tends to be faster than textures, because uses a native format.

Because this uses a native format, a renderbuffer cannot be attached to a shader program and used as a sampler.